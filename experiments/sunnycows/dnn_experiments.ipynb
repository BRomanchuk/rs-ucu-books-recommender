{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/16crnc792zg2yr78zf0qg0j40000gq/T/ipykernel_3201/914109045.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv('../../data/Users.csv', delimiter=';')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "users = pd.read_csv('../../data/Users.csv', delimiter=';')\n",
    "books = pd.read_csv('../../data/Books.csv', delimiter=';', dtype={'ISBN': str, 'Title': str, 'Author': str, 'Year': np.int16, 'Publisher': str})\n",
    "ratings = pd.read_csv('../../data/Ratings.csv', delimiter=';', dtype={'User-ID': np.int32, 'ISBN': str, 'Rating': np.int8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users records: 278859\n",
      "Countries 1476 Ages 167151\n"
     ]
    }
   ],
   "source": [
    "print('Users records:', len(users))\n",
    "users['Countries'] = [x if (not isinstance(x, (int, float)) and not x.isnumeric()) else None for x in users['Age']]\n",
    "users['Age'] = [float(x) if (isinstance(x, (str)) and x.isnumeric()) else None for x in users['Age']]\n",
    "print('Countries', users['Countries'].notna().sum(), 'Ages', users['Age'].notna().sum())\n",
    "\n",
    "users.drop(columns=['Countries'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105283,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()\n",
    "ratings['User-ID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1149780, 3)\n",
      "(433671, 3)\n"
     ]
    }
   ],
   "source": [
    "print(ratings.shape)\n",
    "print(ratings[ratings.Rating > 0].shape)\n",
    "\n",
    "ratings = ratings[ratings.Rating > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.drop_duplicates(subset='ISBN', inplace=True)\n",
    "books = books.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated books (185973,) (271378, 6)\n",
      "Books not rated: 121536\n"
     ]
    }
   ],
   "source": [
    "print(\"Rated books\", ratings['ISBN'].unique().shape, books.shape)\n",
    "\n",
    "all_books_set = set(books['ISBN'])\n",
    "rated_books_set = set(ratings['ISBN'])\n",
    "unrated_books = list(all_books_set - rated_books_set)\n",
    "\n",
    "print(\"Books not rated:\", len(unrated_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp; Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        ISBN                                              Title  \\\n",
       "0      0  0195153448                                Classical Mythology   \n",
       "1      1  0002005018                                       Clara Callan   \n",
       "2      2  0060973129                               Decision in Normandy   \n",
       "3      3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4      4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 Author  Year                Publisher  \n",
       "0    Mark P. O. Morford  2002  Oxford University Press  \n",
       "1  Richard Bruce Wright  2001    HarperFlamingo Canada  \n",
       "2          Carlo D'Este  1991          HarperPerennial  \n",
       "3      Gina Bari Kolata  1999     Farrar Straus Giroux  \n",
       "4       E. J. W. Barber  1999   W. W. Norton & Company  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User-ID   Age\n",
       "0       1   NaN\n",
       "1       2  18.0\n",
       "2       3   NaN\n",
       "3       4  17.0\n",
       "4       5   NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>276736</td>\n",
       "      <td>3257224281</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>276737</td>\n",
       "      <td>0600570967</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Rating\n",
       "1   276726  0155061224       5\n",
       "3   276729  052165615X       3\n",
       "4   276729  0521795028       6\n",
       "6   276736  3257224281       8\n",
       "7   276737  0600570967       6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User_ID_encoded  ISBN_encoded  Rating   Age  Author_encoded  Year  \\\n",
      "0            67542         13121       5  32.0           31470  2001   \n",
      "1            67543         61684       3  16.0           47694  1999   \n",
      "2            67543         61704       6  16.0           56133  2001   \n",
      "3            67544         38768       7  32.0           24910  2001   \n",
      "4            67545          3136       9  25.0           49200  2003   \n",
      "\n",
      "   Publisher_encoded  \n",
      "0               4785  \n",
      "1               1805  \n",
      "2               1805  \n",
      "3               2953  \n",
      "4               4635  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Handle missing values\n",
    "books['Year'] = books['Year'].fillna(books['Year'].median())\n",
    "users['Age'] = users['Age'].fillna(users['Age'].median())\n",
    "\n",
    "books.dropna(inplace=True)\n",
    "users.dropna(inplace=True)\n",
    "ratings.dropna(inplace=True)\n",
    "\n",
    "users['User-ID'] = pd.to_numeric(users['User-ID'], errors='coerce')\n",
    "\n",
    "# Encode categorical variables\n",
    "isbn_encoder = LabelEncoder()\n",
    "author_encoder = LabelEncoder()\n",
    "publisher_encoder = LabelEncoder()\n",
    "user_encoder = LabelEncoder()\n",
    "country_encoder = LabelEncoder()\n",
    "\n",
    "# Merge datasets\n",
    "ratings_users_merged = ratings.merge(users, left_on='User-ID', right_on='User-ID')\n",
    "final_df = ratings_users_merged.merge(books, left_on='ISBN', right_on='ISBN')\n",
    "\n",
    "final_df['ISBN_encoded'] = isbn_encoder.fit_transform(final_df['ISBN'])\n",
    "final_df['Author_encoded'] = author_encoder.fit_transform(final_df['Author'])\n",
    "final_df['Publisher_encoded'] = publisher_encoder.fit_transform(final_df['Publisher'])\n",
    "final_df['User_ID_encoded'] = user_encoder.fit_transform(final_df['User-ID'])\n",
    "\n",
    "# Select relevant columns\n",
    "final_df = final_df[['User_ID_encoded', 'ISBN_encoded', 'Rating', 'Age', 'Author_encoded', 'Year', 'Publisher_encoded']]\n",
    "\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = np.array(final_df[['User_ID_encoded', 'Age']])\n",
    "item_features = np.array(final_df[['ISBN_encoded', 'Author_encoded', 'Year', 'Publisher_encoded']])\n",
    "ratings = np.array(final_df['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:05<01:37,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 395.6460277005737 mse: tensor(156535.7969, grad_fn=<MseLossBackward0>) mae: 351.81363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:09<01:19,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 4464.954927115793 mse: tensor(19935820., grad_fn=<MseLossBackward0>) mae: 3937.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:12<01:10,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1519.3060907665676 mse: tensor(2308291., grad_fn=<MseLossBackward0>) mae: 1342.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:16<01:02,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 771.4356964750682 mse: tensor(595113.0625, grad_fn=<MseLossBackward0>) mae: 679.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:20<00:57,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1762.9278439439504 mse: tensor(3107915., grad_fn=<MseLossBackward0>) mae: 1559.5446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:23<00:52,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1821.5645657932555 mse: tensor(3318098., grad_fn=<MseLossBackward0>) mae: 1614.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:27<00:48,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1446.8131983882897 mse: tensor(2093268.3750, grad_fn=<MseLossBackward0>) mae: 1290.4834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:30<00:44,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 924.7293370659585 mse: tensor(855124.2500, grad_fn=<MseLossBackward0>) mae: 833.47943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:34<00:40,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 371.9981137454492 mse: tensor(138382.5938, grad_fn=<MseLossBackward0>) mae: 344.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:38<00:36,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 180.15496852995105 mse: tensor(32455.8203, grad_fn=<MseLossBackward0>) mae: 155.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:41<00:33,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 565.8189315725749 mse: tensor(320151.0625, grad_fn=<MseLossBackward0>) mae: 482.23376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:45<00:29,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 757.8660517594686 mse: tensor(574361., grad_fn=<MseLossBackward0>) mae: 646.7525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:49<00:25,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 799.0913775286764 mse: tensor(638546.9375, grad_fn=<MseLossBackward0>) mae: 684.2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:52<00:21,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 731.3244073197767 mse: tensor(534835.3750, grad_fn=<MseLossBackward0>) mae: 628.4637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:56<00:18,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 583.2226948319509 mse: tensor(340148.6875, grad_fn=<MseLossBackward0>) mae: 503.73254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:00<00:14,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 394.3238319317807 mse: tensor(155491.2969, grad_fn=<MseLossBackward0>) mae: 342.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:03<00:10,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 187.76506054351262 mse: tensor(35255.7109, grad_fn=<MseLossBackward0>) mae: 165.70284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [01:07<00:07,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 24.73370111397996 mse: tensor(611.7560, grad_fn=<MseLossBackward0>) mae: 20.816355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [01:10<00:03,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 193.13200962133325 mse: tensor(37299.9766, grad_fn=<MseLossBackward0>) mae: 161.59169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:14<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 308.90418477978756 mse: tensor(95421.7891, grad_fn=<MseLossBackward0>) mae: 260.51196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 134706.5625\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Split data\n",
    "train_data, test_data, train_ratings, test_ratings = train_test_split(\n",
    "    final_df.drop('Rating', axis=1),\n",
    "    final_df['Rating'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_data_tensor = torch.tensor(train_data.values, dtype=torch.float32)\n",
    "train_ratings_tensor = torch.tensor(train_ratings.values, dtype=torch.float32)\n",
    "test_data_tensor = torch.tensor(test_data.values, dtype=torch.float32)\n",
    "test_ratings_tensor = torch.tensor(test_ratings.values, dtype=torch.float32)\n",
    "\n",
    "# Define the model\n",
    "class DNNRecommenderWithFeatures(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_user_features, num_item_features, embedding_dim, hidden_dim):\n",
    "        super(DNNRecommenderWithFeatures, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        self.user_feature_layer = nn.Linear(num_user_features, embedding_dim)\n",
    "        self.item_feature_layer = nn.Linear(num_item_features, embedding_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(embedding_dim * 2 * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, 1)\n",
    "        \n",
    "    def forward(self, user_ids, item_ids, user_features, item_features):\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        \n",
    "        user_feature_embeds = self.user_feature_layer(user_features)\n",
    "        item_feature_embeds = self.item_feature_layer(item_features)\n",
    "        \n",
    "        user_combined = torch.cat([user_embeds, user_feature_embeds], dim=1)\n",
    "        item_combined = torch.cat([item_embeds, item_feature_embeds], dim=1)\n",
    "        \n",
    "        x = torch.cat([user_combined, item_combined], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_items = len(isbn_encoder.classes_)\n",
    "\n",
    "user_ids = train_data_tensor[:, 0].long()\n",
    "item_ids = train_data_tensor[:, 1].long()\n",
    "user_features = train_data_tensor[:, 2:3]\n",
    "item_features = train_data_tensor[:, 3:]\n",
    "\n",
    "num_user_features = user_features.shape[1]  # Age\n",
    "num_item_features = item_features.shape[1]  # Author_encoded, Year, and Publisher_encoded\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_dim = 512\n",
    "\n",
    "model = DNNRecommenderWithFeatures(num_users, num_items, num_user_features, num_item_features, embedding_dim, hidden_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(user_ids, item_ids, user_features, item_features)\n",
    "    loss = criterion(predictions, train_ratings_tensor)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "    diff = (predictions-train_ratings_tensor).detach().numpy()\n",
    "    rmse = (np.sum(diff**2)/len(train_data_tensor))**0.5\n",
    "\n",
    "    abs_diff = np.absolute(diff)\n",
    "    mae = np.mean(abs_diff)\n",
    "    # if epoch % 10 == 0:\n",
    "    print(\"rmse:\", rmse, \"mse:\",loss, \"mae:\",mae)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    user_ids = test_data_tensor[:, 0].long()\n",
    "    item_ids = test_data_tensor[:, 1].long()\n",
    "    user_features = test_data_tensor[:, 2:3]\n",
    "    item_features = test_data_tensor[:, 3:]\n",
    "    \n",
    "    predictions = model(user_ids, item_ids, user_features, item_features)\n",
    "    test_loss = criterion(predictions, test_ratings_tensor)\n",
    "    print(f'Test Loss: {test_loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
