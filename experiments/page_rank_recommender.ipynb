{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/Ratings.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out users or books with very few interactions to reduce noise (optional)\n",
    "user_threshold = 5\n",
    "book_threshold = 5\n",
    "\n",
    "user_counts = data['User-ID'].value_counts()\n",
    "book_counts = data['ISBN'].value_counts()\n",
    "\n",
    "filtered_data = data[data['User-ID'].isin(user_counts[user_counts >= user_threshold].index)]\n",
    "filtered_data = filtered_data[filtered_data['ISBN'].isin(book_counts[book_counts >= book_threshold].index)]\n",
    "\n",
    "# Create a bipartite graph\n",
    "B = nx.Graph()\n",
    "\n",
    "# Add nodes with the bipartite attribute\n",
    "users = list(filtered_data['User-ID'].unique())\n",
    "books = list(filtered_data['ISBN'].unique())\n",
    "\n",
    "B.add_nodes_from(users, bipartite=0)  # Add user nodes\n",
    "B.add_nodes_from(books, bipartite=1)  # Add book nodes\n",
    "\n",
    "# Add edges between users and books based on interactions\n",
    "edges = list(filtered_data[['User-ID', 'ISBN']].itertuples(index=False, name=None))\n",
    "B.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(G, alpha=0.85, max_iter=100, tol=1e-06):\n",
    "    \"\"\"\n",
    "    Compute PageRank for each node in the graph.\n",
    "\n",
    "    Parameters:\n",
    "    - G: The graph (NetworkX graph)\n",
    "    - alpha: Damping factor, typically 0.85\n",
    "    - max_iter: Maximum number of iterations\n",
    "    - tol: Tolerance to check convergence\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary of nodes with PageRank as value\n",
    "    \"\"\"\n",
    "    nodes = G.nodes()\n",
    "    N = len(nodes)\n",
    "\n",
    "    # Initialize the PageRank dict with equal probability for each node\n",
    "    pagerank = {node: 1 / N for node in nodes}\n",
    "\n",
    "    for i in tqdm(range(max_iter)):\n",
    "        prev_pagerank = pagerank.copy()\n",
    "        for node in nodes:\n",
    "            rank_sum = 0\n",
    "            for neighbor in G.neighbors(node):\n",
    "                rank_sum += prev_pagerank[neighbor] / len(list(G.neighbors(neighbor)))\n",
    "            pagerank[node] = (1 - alpha) / N + alpha * rank_sum\n",
    "\n",
    "        # Check for convergence\n",
    "        if sum(abs(pagerank[node] - prev_pagerank[node]) for node in nodes) < tol:\n",
    "            print(f\"Converged after {i + 1} iterations.\")\n",
    "            break\n",
    "\n",
    "    return pagerank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [04:53<01:04,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 83 iterations.\n",
      "Top 10 Books by PageRank:\n",
      "             Node  PageRank\n",
      "22222  0971880107  0.001388\n",
      "22206  0316666343  0.000655\n",
      "22208  0385504209  0.000483\n",
      "23629  0060928336  0.000388\n",
      "22659  0312195516  0.000361\n",
      "22302  059035342X  0.000329\n",
      "22720  0142001740  0.000327\n",
      "23362  0679781587  0.000326\n",
      "26012  067976402X  0.000323\n",
      "23031  0671027360  0.000322\n",
      "\n",
      "Top 10 Users by PageRank:\n",
      "         Node  PageRank\n",
      "988     11676  0.006272\n",
      "3022    35859  0.002464\n",
      "12358  153662  0.002276\n",
      "15843  198711  0.001844\n",
      "8029    98391  0.001652\n",
      "6284    76352  0.001632\n",
      "16958  212898  0.001299\n",
      "1396    16795  0.001262\n",
      "16304  204864  0.001232\n",
      "18071  227447  0.001136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate PageRank\n",
    "pr = pagerank(B)\n",
    "\n",
    "# Convert the result to a DataFrame for easier analysis\n",
    "pr_df = pd.DataFrame(list(pr.items()), columns=['Node', 'PageRank'])\n",
    "\n",
    "# Separate users and books\n",
    "user_pr = pr_df[pr_df['Node'].isin(users)].sort_values(by='PageRank', ascending=False)\n",
    "book_pr = pr_df[pr_df['Node'].isin(books)].sort_values(by='PageRank', ascending=False)\n",
    "\n",
    "# Display top 10 books based on PageRank\n",
    "print(\"Top 10 Books by PageRank:\")\n",
    "print(book_pr.head(10))\n",
    "\n",
    "# Display top 10 users based on PageRank (optional)\n",
    "print(\"\\nTop 10 Users by PageRank:\")\n",
    "print(user_pr.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv39",
   "language": "python",
   "name": ".venv39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
