{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential recommender\n",
    "The idea of this task is to use a sequential model for recommending. For this task we only use the order of items users recommended. Order is defined by the augmented timestamps was also tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ratings: 10244\n",
      "Total ratings (dropna, duplicates): 10244\n",
      "Total ratings (drop zeroes): 10244\n",
      "Total ratings (users rated <5 books excluded): 9509\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ratings_df = pd.read_csv('../../data/Ratings_merged_emb_time.csv')\n",
    "print(\"Total ratings:\", ratings_df.shape[0])\n",
    "\n",
    "ratings_df = ratings_df.dropna()\n",
    "ratings_df = ratings_df.drop_duplicates()\n",
    "print(\"Total ratings (dropna, duplicates):\", ratings_df.shape[0])\n",
    "\n",
    "ratings_df = ratings_df[ratings_df['label'] != 0]\n",
    "print(\"Total ratings (drop zeroes):\", ratings_df.shape[0])\n",
    "\n",
    "ratings_df = ratings_df.sort_values(by=['user', 'time'])\n",
    "\n",
    "rating_count=pd.DataFrame(ratings_df[\"user\"].value_counts())\n",
    "u_threshold=rating_count[rating_count[\"count\"]<5].index\n",
    "ratings_df=ratings_df[~ratings_df[\"user\"].isin(u_threshold)]\n",
    "\n",
    "print('Total ratings (users rated <5 books excluded):', ratings_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "      <th>Age</th>\n",
       "      <th>pca_dim_1</th>\n",
       "      <th>pca_dim_2</th>\n",
       "      <th>pca_dim_3</th>\n",
       "      <th>pca_dim_4</th>\n",
       "      <th>pca_dim_5</th>\n",
       "      <th>pca_dim_6</th>\n",
       "      <th>pca_dim_7</th>\n",
       "      <th>pca_dim_8</th>\n",
       "      <th>pca_dim_9</th>\n",
       "      <th>pca_dim_10</th>\n",
       "      <th>Year</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>1435.0</td>\n",
       "      <td>0394742591</td>\n",
       "      <td>7.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.034801</td>\n",
       "      <td>0.056853</td>\n",
       "      <td>0.057859</td>\n",
       "      <td>-0.075493</td>\n",
       "      <td>-0.051257</td>\n",
       "      <td>-0.101462</td>\n",
       "      <td>-0.039232</td>\n",
       "      <td>0.108641</td>\n",
       "      <td>0.065861</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1.085904e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>1435.0</td>\n",
       "      <td>0802713815</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>-0.067927</td>\n",
       "      <td>-0.057565</td>\n",
       "      <td>-0.017031</td>\n",
       "      <td>-0.043261</td>\n",
       "      <td>-0.068278</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>-0.013976</td>\n",
       "      <td>-0.007283</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1.136215e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>1435.0</td>\n",
       "      <td>0618127453</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.020441</td>\n",
       "      <td>0.135455</td>\n",
       "      <td>0.150682</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.049744</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>-0.056898</td>\n",
       "      <td>0.036038</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>-0.058842</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1.289050e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>1435.0</td>\n",
       "      <td>0060977477</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.161237</td>\n",
       "      <td>-0.018448</td>\n",
       "      <td>-0.002502</td>\n",
       "      <td>0.020070</td>\n",
       "      <td>0.078334</td>\n",
       "      <td>-0.037889</td>\n",
       "      <td>-0.037328</td>\n",
       "      <td>-0.101203</td>\n",
       "      <td>-0.066508</td>\n",
       "      <td>0.112463</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.302138e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>1435.0</td>\n",
       "      <td>0812590236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.027918</td>\n",
       "      <td>-0.035166</td>\n",
       "      <td>0.072684</td>\n",
       "      <td>0.113108</td>\n",
       "      <td>-0.078089</td>\n",
       "      <td>-0.059030</td>\n",
       "      <td>-0.003526</td>\n",
       "      <td>0.100786</td>\n",
       "      <td>0.102507</td>\n",
       "      <td>-0.052539</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.541256e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user        item  label   Age  pca_dim_1  pca_dim_2  pca_dim_3  \\\n",
       "1565  1435.0  0394742591    7.0  36.0   0.034801   0.056853   0.057859   \n",
       "1568  1435.0  0802713815    5.0  36.0   0.124400   0.048072  -0.067927   \n",
       "1566  1435.0  0618127453    9.0  36.0  -0.020441   0.135455   0.150682   \n",
       "1564  1435.0  0060977477    5.0  36.0   0.161237  -0.018448  -0.002502   \n",
       "1567  1435.0  0812590236    4.0  36.0   0.027918  -0.035166   0.072684   \n",
       "\n",
       "      pca_dim_4  pca_dim_5  pca_dim_6  pca_dim_7  pca_dim_8  pca_dim_9  \\\n",
       "1565  -0.075493  -0.051257  -0.101462  -0.039232   0.108641   0.065861   \n",
       "1568  -0.057565  -0.017031  -0.043261  -0.068278   0.005158  -0.013976   \n",
       "1566  -0.013349  -0.049744   0.002055  -0.056898   0.036038   0.010957   \n",
       "1564   0.020070   0.078334  -0.037889  -0.037328  -0.101203  -0.066508   \n",
       "1567   0.113108  -0.078089  -0.059030  -0.003526   0.100786   0.102507   \n",
       "\n",
       "      pca_dim_10    Year          time  \n",
       "1565    0.026866  1980.0  1.085904e+09  \n",
       "1568   -0.007283  2001.0  1.136215e+09  \n",
       "1566   -0.058842  2001.0  1.289050e+09  \n",
       "1564    0.112463  1999.0  1.302138e+09  \n",
       "1567   -0.052539  2000.0  1.541256e+09  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "book_encoder = LabelEncoder()\n",
    "ratings_df['item'] = book_encoder.fit_transform(ratings_df['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, eval_df = train_test_split(ratings_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 23:02:02.428840: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2593], [2593, 6256], [2593, 6256, 4815], [2593, 6256, 4815, 310], [1712], [1712, 5135], [1712, 5135, 4077], [1712, 5135, 4077, 3367], [1712, 5135, 4077, 3367, 1793], [1712, 5135, 4077, 3367, 1793, 2053]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/16crnc792zg2yr78zf0qg0j40000gq/T/ipykernel_37786/1772880186.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_grouped = train_df.groupby('user').apply(lambda x: x.sort_values(by='time'))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "user_grouped = train_df.groupby('user').apply(lambda x: x.sort_values(by='time'))\n",
    "\n",
    "sequences = []\n",
    "next_books = []\n",
    "\n",
    "for user_id, user_data in user_grouped.groupby(level=0):\n",
    "    user_books = user_data['item'].tolist()\n",
    "    for i in range(1, len(user_books)):\n",
    "        sequences.append(user_books[:i])\n",
    "        next_books.append(user_books[i])\n",
    "\n",
    "print(sequences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 23:02:06.422764: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 121s 1s/step - loss: 8.9886 - accuracy: 3.4459e-04 - val_loss: 9.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 122s 1s/step - loss: 8.9941 - accuracy: 8.6147e-04 - val_loss: 10.3122 - val_accuracy: 6.8871e-04\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 126s 1s/step - loss: 8.8255 - accuracy: 6.8918e-04 - val_loss: 10.4917 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 122s 1s/step - loss: 8.7329 - accuracy: 5.1688e-04 - val_loss: 10.4981 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 122s 1s/step - loss: 8.6906 - accuracy: 5.1688e-04 - val_loss: 10.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 137s 2s/step - loss: 8.6484 - accuracy: 6.8918e-04 - val_loss: 10.8452 - val_accuracy: 6.8871e-04\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 168s 2s/step - loss: 8.6400 - accuracy: 8.6147e-04 - val_loss: 11.1450 - val_accuracy: 6.8871e-04\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 126s 1s/step - loss: 8.6230 - accuracy: 6.8918e-04 - val_loss: 11.6219 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 127s 1s/step - loss: 8.5954 - accuracy: 8.6147e-04 - val_loss: 12.1207 - val_accuracy: 0.0034\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 128s 1s/step - loss: 8.5645 - accuracy: 0.0014 - val_loss: 11.8522 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4053d5c70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Padding sequences to the same length\n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "sequences_padded = pad_sequences(sequences, maxlen=max_sequence_len)\n",
    "\n",
    "# Convert labels to categorical\n",
    "next_books = np.array(next_books)\n",
    "num_books = len(book_encoder.classes_)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(sequences_padded, next_books, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "embedding_dim = 50\n",
    "\n",
    "input_layer = Input(shape=(max_sequence_len,))\n",
    "embedding_layer = Embedding(input_dim=num_books, output_dim=embedding_dim, input_length=max_sequence_len)(input_layer)\n",
    "lstm_layer = LSTM(128, return_sequences=False)(embedding_layer)\n",
    "output_layer = Dense(num_books, activation='softmax')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/16crnc792zg2yr78zf0qg0j40000gq/T/ipykernel_37786/3277511587.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_grouped = eval_df.groupby('user').apply(lambda x: x.sort_values(by='time'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 13s 252ms/step\n",
      "Precision@10: 0.0044\n",
      "Recall@10: 0.0044\n",
      "NDCG@10: 0.2802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "top_k = 10\n",
    "eval_df = eval_df.sort_values(by=['user', 'time'])\n",
    "\n",
    "# Create sequences of interactions per user\n",
    "user_grouped = eval_df.groupby('user').apply(lambda x: x.sort_values(by='time'))\n",
    "\n",
    "# Generate input sequences and labels for evaluation\n",
    "eval_sequences = []\n",
    "true_labels = []\n",
    "\n",
    "for user_id, user_data in user_grouped.groupby(level=0):\n",
    "    user_books = user_data['item'].tolist()\n",
    "    for i in range(1, len(user_books)):\n",
    "        eval_sequences.append(user_books[:i])\n",
    "        true_labels.append(user_books[i])\n",
    "\n",
    "# Padding sequences to the same length\n",
    "eval_sequences_padded = pad_sequences(eval_sequences, maxlen=max_sequence_len)\n",
    "\n",
    "# Predict the next book\n",
    "predictions = model.predict(eval_sequences_padded, verbose=1)\n",
    "\n",
    "# Calculate precision, recall, and NDCG\n",
    "precisions = []\n",
    "recalls = []\n",
    "ndcgs = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    top_k_predictions = np.argsort(predictions[i])[-top_k:][::-1]  # Get top k predictions\n",
    "    true_label = true_labels[i]\n",
    "\n",
    "    # Precision@k: Did the model recommend the true book within the top k?\n",
    "    precision = 1 if true_label in top_k_predictions else 0\n",
    "    precisions.append(precision)\n",
    "\n",
    "    # Recall@k: Since there's only one true book, recall is the same as precision here.\n",
    "    recalls.append(precision)\n",
    "\n",
    "    # NDCG@k: Evaluates the ranking of the true book in the top k predictions\n",
    "    rank = np.where(top_k_predictions == true_label)[0][0] + 1 if true_label in top_k_predictions else top_k + 1\n",
    "    dcg = 1 / np.log2(rank + 1)\n",
    "    idcg = 1.0  # Ideal DCG is 1 when the true book is ranked first\n",
    "    ndcg = dcg / idcg\n",
    "    ndcgs.append(ndcg)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_ndcg = np.mean(ndcgs)\n",
    "\n",
    "print(f\"Precision@{top_k}: {avg_precision:.4f}\")\n",
    "print(f\"Recall@{top_k}: {avg_recall:.4f}\")\n",
    "print(f\"NDCG@{top_k}: {avg_ndcg:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
